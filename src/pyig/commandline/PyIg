#!/usr/bin/env python
import os
import gzip
import sys
from Bio import SeqIO
from pyig.backend.PyIgArgumentParser import PyIgArgumentParser
from pyig.backend.SplitFasta import split_fasta
from pyig.backend.IgBlastRun import IgBlastRun
from multiprocessing import Process, Queue

if sys.version_info < (2, 7):
    raise OSError("You need python 2.7.5 or higher, rerun with \%python2.7 /path/to/PyIg")


def files_zipper(list_of_files, outfile, out_format="json"):
    '''Gzip multiple fiels together'''
    outfile = outfile.split('.json')[0].split('.json.gz')[0]
    print "Zipping up file to {0}.json.gz".format(outfile)
    with gzip.open(outfile+".json.gz", 'wb') as final_out:

        if (out_format == "csv"):
            headers = ['Sequence Id', 'Query Sequence', 'Chain type', 'Format Type', 'Species', 'Top V Hit', 'Top D Hit', 'Top J Hit', 'Productive', 'Productive CDR3', 'Strand', 'Framework 1 Nucleotides', 'Framework 2 Nucleotides', 'Framework 3 Nucleotides', 'Framework 4 Nucleotides', 'CDR1 Nucleotides', 'CDR2 Nucleotides', 'CDR3 Nucleotides', 'Framework 1 AA', 'Framework 2 AA', 'Framework 3 AA', 'Framework 4 AA', 'Framework 1 AA Length', 'Framework 2 AA Length', 'Framework 3 AA Length', 'Framework 4 AA Length', 'CDR1 AA', 'CDR2 AA', 'CDR3 AA', 'CDR1 AA Length', 'CDR2 AA Length', 'CDR3 AA Length', 'Total V Alignment Matches', 'Total V Alignment Mismatches', 'Total V Alignment Length', 'Total V Alignment Gaps', 'Total V Alignment Identity', 'FW1 Alignment From', 'FW1 Alignment To', 'FW1 Alignment Matches', 'FW1 Alignment Mismatches', 'FW1 Alignment Length', 'FW1 Alignment Gaps', 'FW1 Alignment Identity', 'FW2 Alignment From', 'FW2 Alignment To', 'FW2 Alignment Matches', 'FW2 Alignment Mismatches', 'FW2 Alignment Length', 'FW2 Alignment Gaps', 'FW2 Alignment Identity', 'FW3 Alignment From', 'FW3 Alignment To', 'FW3 Alignment Matches', 'FW3 Alignment Mismatches', 'FW3 Alignment Length', 'FW3 Alignment Gaps', 'FW3 Alignment Identity', 'CDR1 Alignment From', 'CDR1 Alignment To', 'CDR1 Alignment Matches', 'CDR1 Alignment Mismatches', 'CDR1 Alignment Length', 'CDR1 Alignment Gaps', 'CDR1 Alignment Identity', 'CDR2 Alignment From', 'CDR2 Alignment To', 'CDR2 Alignment Matches', 'CDR2 Alignment Mismatches', 'CDR2 Alignment Length', 'CDR2 Alignment Gaps', 'CDR2 Alignment Identity', 'CDR3 Alignment From', 'CDR3 Alignment To', 'CDR3 Alignment Matches', 'CDR3 Alignment Mismatches', 'CDR3 Alignment Length', 'CDR3 Alignment Gaps', 'CDR3 Alignment Identity', 'Junction V-End', 'V-D Junction', 'Junction D-Gene', 'D-J Junction', 'Junction J-Start', 'D or J Junction', 'Junction Merged', 'V-J Junction', 'Stop Codon', 'V-J frame', 'V-Gene Rank_1 Query id', 'V-Gene Rank_1 Subject id', 'V-Gene Rank_1 Percent identity', 'V-Gene Rank_1 Alignment length', 'V-Gene Rank_1 Mismatches', 'V-Gene Rank_1 Gap opens', 'V-Gene Rank_1 Gaps', 'V-Gene Rank_1 Q. start', 'V-Gene Rank_1 Q. end', 'V-Gene Rank_1 S. start', 'V-Gene Rank_1 S. end', 'V-Gene Rank_1 Evalue', 'V-Gene Rank_1 Bit score', 'D-Gene Rank_1 Query id', 'D-Gene Rank_1 Subject id', 'D-Gene Rank_1 Percent identity', 'D-Gene Rank_1 Alignment length', 'D-Gene Rank_1 Mismatches', 'D-Gene Rank_1 Gap opens', 'D-Gene Rank_1 Gaps', 'D-Gene Rank_1 Q. start', 'D-Gene Rank_1 Q. end', 'D-Gene Rank_1 S. start', 'D-Gene Rank_1 S. end', 'D-Gene Rank_1 Evalue', 'D-Gene Rank_1 Bit score', 'J-Gene Rank_1 Query id', 'J-Gene Rank_1 Subject id', 'J-Gene Rank_1 Percent identity', 'J-Gene Rank_1 Alignment length', 'J-Gene Rank_1 Mismatches', 'J-Gene Rank_1 Gap opens', 'J-Gene Rank_1 Gaps', 'J-Gene Rank_1 Q. start', 'J-Gene Rank_1 Q. end', 'J-Gene Rank_1 S. start', 'J-Gene Rank_1 S. end', 'J-Gene Rank_1 Evalue', 'J-Gene Rank_1 Bit score']
            final_out.write("\t".join(headers))
            final_out.write("\n")

        for file in list_of_files:
            with open(file) as finfile:
                for line in finfile:
                    final_out.write(line)
            os.remove(file)


def file_zipper(file, outfile, out_format="json"):
    '''zip one file and delete it'''
    outfile = outfile.split('.json')[0].split('.json.gz')[0]
    print "Zipping up single file to {0}.json.gz".format(outfile)
    f_in = open(file, 'rb')
    f_out = gzip.open(outfile+".json.gz", 'wb')

    if (out_format == "csv"):
        headers = ['Sequence Id', 'Query Sequence', 'Chain type', 'Format Type', 'Species', 'Top V Hit', 'Top D Hit', 'Top J Hit', 'Productive', 'Productive CDR3', 'Strand', 'Framework 1 Nucleotides', 'Framework 2 Nucleotides', 'Framework 3 Nucleotides', 'Framework 4 Nucleotides', 'CDR1 Nucleotides', 'CDR2 Nucleotides', 'CDR3 Nucleotides', 'Framework 1 AA', 'Framework 2 AA', 'Framework 3 AA', 'Framework 4 AA', 'Framework 1 AA Length', 'Framework 2 AA Length', 'Framework 3 AA Length', 'Framework 4 AA Length', 'CDR1 AA', 'CDR2 AA', 'CDR3 AA', 'CDR1 AA Length', 'CDR2 AA Length', 'CDR3 AA Length', 'Total V Alignment Matches', 'Total V Alignment Mismatches', 'Total V Alignment Length', 'Total V Alignment Gaps', 'Total V Alignment Identity', 'FW1 Alignment From', 'FW1 Alignment To', 'FW1 Alignment Matches', 'FW1 Alignment Mismatches', 'FW1 Alignment Length', 'FW1 Alignment Gaps', 'FW1 Alignment Identity', 'FW2 Alignment From', 'FW2 Alignment To', 'FW2 Alignment Matches', 'FW2 Alignment Mismatches', 'FW2 Alignment Length', 'FW2 Alignment Gaps', 'FW2 Alignment Identity', 'FW3 Alignment From', 'FW3 Alignment To', 'FW3 Alignment Matches', 'FW3 Alignment Mismatches', 'FW3 Alignment Length', 'FW3 Alignment Gaps', 'FW3 Alignment Identity', 'CDR1 Alignment From', 'CDR1 Alignment To', 'CDR1 Alignment Matches', 'CDR1 Alignment Mismatches', 'CDR1 Alignment Length', 'CDR1 Alignment Gaps', 'CDR1 Alignment Identity', 'CDR2 Alignment From', 'CDR2 Alignment To', 'CDR2 Alignment Matches', 'CDR2 Alignment Mismatches', 'CDR2 Alignment Length', 'CDR2 Alignment Gaps', 'CDR2 Alignment Identity', 'CDR3 Alignment From', 'CDR3 Alignment To', 'CDR3 Alignment Matches', 'CDR3 Alignment Mismatches', 'CDR3 Alignment Length', 'CDR3 Alignment Gaps', 'CDR3 Alignment Identity', 'Junction V-End', 'V-D Junction', 'Junction D-Gene', 'D-J Junction', 'Junction J-Start', 'D or J Junction', 'Junction Merged', 'Stop Codon', 'V-J frame', 'V-Gene Rank_1 Query id', 'V-Gene Rank_1 Subject id', 'V-Gene Rank_1 Percent identity', 'V-Gene Rank_1 Alignment length', 'V-Gene Rank_1 Mismatches', 'V-Gene Rank_1 Gap opens', 'V-Gene Rank_1 Gaps', 'V-Gene Rank_1 Q. start', 'V-Gene Rank_1 Q. end', 'V-Gene Rank_1 S. start', 'V-Gene Rank_1 S. end', 'V-Gene Rank_1 Evalue', 'V-Gene Rank_1 Bit score', 'D-Gene Rank_1 Query id', 'D-Gene Rank_1 Subject id', 'D-Gene Rank_1 Percent identity', 'D-Gene Rank_1 Alignment length', 'D-Gene Rank_1 Mismatches', 'D-Gene Rank_1 Gap opens', 'D-Gene Rank_1 Gaps', 'D-Gene Rank_1 Q. start', 'D-Gene Rank_1 Q. end', 'D-Gene Rank_1 S. start', 'D-Gene Rank_1 S. end', 'D-Gene Rank_1 Evalue', 'D-Gene Rank_1 Bit score', 'J-Gene Rank_1 Query id', 'J-Gene Rank_1 Subject id', 'J-Gene Rank_1 Percent identity', 'J-Gene Rank_1 Alignment length', 'J-Gene Rank_1 Mismatches', 'J-Gene Rank_1 Gap opens', 'J-Gene Rank_1 Gaps', 'J-Gene Rank_1 Q. start', 'J-Gene Rank_1 Q. end', 'J-Gene Rank_1 S. start', 'J-Gene Rank_1 S. end', 'J-Gene Rank_1 Evalue', 'J-Gene Rank_1 Bit score']
        f_out.write("\t".join(headers))
        f_out.write("\n")

    f_out.writelines(f_in)
    f_out.close()
    f_in.close()
    os.remove(file)


def get_seqs_dict(fasta_file):
    f_dict = {}
    for seq in SeqIO.parse(fasta_file, 'fasta'):
        f_dict[seq.id] = str(seq.seq)
    return f_dict


def main(PyIgParse):
    # for multiproc, set up list to hold output and a queue to hold the results of each job.
    # Queue can be passed around to multiple processors and lives out of scope
    to_join = []
    queue = Queue()
    jobs = []

    # Grab argments from input dictionary
    fasta_file = PyIgParse['query']
    num_procs = int(PyIgParse['multi'])
    if PyIgParse['out']:
        output_file = PyIgParse['out']
    else:
        output_file = fasta_file.split('.')[0]

    # determine if its multi-procs
    if num_procs > 1:

        # first split fasta file to temporary files
        split_fasta_file_names = split_fasta(
            num_procs, fasta_file, delete=False)

        # iterate through each new fasta file name
        # giving it to a new process instance that is the length of how
        # many processors we have. So number of processors = how many fasta files
        for num, name in enumerate(split_fasta_file_names, start=1):
            print "Running IgBlast on processor {0}".format(num)

            # Set up run class
            IgBlast = IgBlastRun(PyIgParse, get_seqs_dict(name), name)

            # P is process class that takes one method and some argument
            p = Process(target=IgBlast.run_single_process, args=(queue, ))

            # add job to list
            jobs.append(p)

            # start job
            p.start()

        for job, temp_file in zip(jobs, split_fasta_file_names):
            # join method actually starts the job
            job.join()

            # now we can fetch the output from the Queue class we gave to the instance
            to_join.append(queue.get())

        # and finally zip up files that come back
        files_zipper(to_join, output_file, PyIgParse['out_format'])

    else:  # single processor
        print "Running IgBlast on single processor"

        # still split fasta file, but it only makes one temp file. this is just so we don't have to write a seperate method
        # for single processors
        split_fasta_file_names = split_fasta(
            1, fasta_file, delete=False)

        query = split_fasta_file_names[0]

        # set up run instance
        IgBlast = IgBlastRun(
            PyIgParse,
            get_seqs_dict(query),
            query
        )

        # Running it like multiprocessing, but only using one processor
        p = Process(target=IgBlast.run_single_process,
                    args=(queue,))
        # start and join the processes
        p.start()
        p.join()

        # zip up the one file at the end
        file_zipper(queue.get(), output_file, PyIgParse['out_format'])


if __name__ == '__main__':
    # grab the command line arguments and call main with the dictonary
    PyIg_ParseDict = PyIgArgumentParser().parse_arguments()
    main(PyIg_ParseDict)
